{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, concatenate, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.applications import VGG16, InceptionV3, ResNet50, EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import pickle\n",
    "\n",
    "def load_csv(csv_file):\n",
    "    return pd.read_csv(csv_file)\n",
    "\n",
    "def fix_level_cat_format(row, separator=' ', replacement=', '):\n",
    "    return eval(row.replace(separator, replacement))\n",
    "\n",
    "def extract_labels(df, column_name='level_cat', fix_func=fix_level_cat_format):\n",
    "    return np.array([fix_func(row) for row in df[column_name].values])\n",
    "\n",
    "def extract_additional_features(df, feature_columns):\n",
    "    return df[feature_columns].values\n",
    "\n",
    "def normalize_features(features, scaler=None):\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "    else:\n",
    "        scaled_features = scaler.transform(features)\n",
    "    return scaled_features, scaler\n",
    "\n",
    "def save_scaler(scaler, scaler_file):\n",
    "    with open(scaler_file, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224), preprocessing_function=preprocess_input):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img = img_to_array(img)\n",
    "    img = preprocessing_function(img)\n",
    "    return img\n",
    "\n",
    "def load_images(image_paths, preprocess_func=load_and_preprocess_image):\n",
    "    return np.array([preprocess_func(path) for path in image_paths])\n",
    "\n",
    "def split_data(images, additional_features, labels, test_size=0.2, random_state=42):\n",
    "    return train_test_split(images, additional_features, labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def create_vgg16_model(input_shape=(224, 224, 3), base_model_weights='imagenet', include_top=False, custom_layers=None):\n",
    "    base_model = VGG16(weights=base_model_weights, include_top=include_top, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    if custom_layers is not None:\n",
    "        for layer in custom_layers:\n",
    "            x = layer(x)\n",
    "    else:\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "    return base_model.input, x\n",
    "\n",
    "def create_inceptionv3_model(input_shape=(299, 299, 3), base_model_weights='imagenet', include_top=False, custom_layers=None):\n",
    "    base_model = InceptionV3(weights=base_model_weights, include_top=include_top, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    if custom_layers is not None:\n",
    "        for layer in custom_layers:\n",
    "            x = layer(x)\n",
    "    else:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "    return base_model.input, x\n",
    "\n",
    "def create_resnet50_model(input_shape=(224, 224, 3), base_model_weights='imagenet', include_top=False, custom_layers=None):\n",
    "    base_model = ResNet50(weights=base_model_weights, include_top=include_top, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    if custom_layers is not None:\n",
    "        for layer in custom_layers:\n",
    "            x = layer(x)\n",
    "    else:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "    return base_model.input, x\n",
    "\n",
    "def create_efficientnetb0_model(input_shape=(224, 224, 3), base_model_weights='imagenet', include_top=False, custom_layers=None):\n",
    "    base_model = EfficientNetB0(weights=base_model_weights, include_top=include_top, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    if custom_layers is not None:\n",
    "        for layer in custom_layers:\n",
    "            x = layer(x)\n",
    "    else:\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "    return base_model.input, x\n",
    "\n",
    "def create_additional_input(shape):\n",
    "    return Input(shape=shape)\n",
    "\n",
    "def create_combined_model(vgg_input, vgg_output, additional_input, num_classes=5, additional_layers=None):\n",
    "    combined = concatenate([vgg_output, additional_input])\n",
    "    if additional_layers is not None:\n",
    "        for layer in additional_layers:\n",
    "            combined = layer(combined)\n",
    "    else:\n",
    "        combined = Dense(128, activation='relu')(combined)\n",
    "        combined = Dropout(0.5)(combined)\n",
    "    final_output = Dense(num_classes, activation='softmax')(combined)\n",
    "    return Model(inputs=[vgg_input, additional_input], outputs=final_output)\n",
    "\n",
    "def compile_and_train_model(model, X_train_img, X_train_feat, y_train, X_test_img, X_test_feat, y_test, callbacks, optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'], epochs=12, batch_size=64):\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    history = model.fit(\n",
    "        [X_train_img, X_train_feat], y_train,\n",
    "        validation_data=([X_test_img, X_test_feat], y_test),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    return history\n",
    "\n",
    "def evaluate_and_save_model(model, X_test_img, X_test_feat, y_test, model_save_path):\n",
    "    loss, accuracy = model.evaluate([X_test_img, X_test_feat], y_test)\n",
    "    print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
    "    model.save(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m 1/34\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:07\u001b[0m 177s/step - accuracy: 0.2969 - loss: 7.4810"
     ]
    }
   ],
   "source": [
    "# Usage example for VGG16\n",
    "csv_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\remaining_dataset.csv'\n",
    "df = load_csv(csv_file)\n",
    "labels = extract_labels(df)\n",
    "additional_features = extract_additional_features(df, ['HbA1c', 'Systolic_BP', 'Diastolic_BP', 'LDL', 'Duration', 'BMI', 'Glucose_SD', 'Triglycerides', 'Microalbuminuria', 'Smoking_years', 'Alcohol_frequency'])\n",
    "additional_features, scaler = normalize_features(additional_features)\n",
    "scaler_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\additional_features_scaler.pkl'\n",
    "save_scaler(scaler, scaler_file)\n",
    "images = load_images(df['full_path'])\n",
    "X_train_img, X_test_img, X_train_feat, X_test_feat, y_train, y_test = split_data(images, additional_features, labels)\n",
    "\n",
    "custom_layers_vgg = [Flatten(), Dense(256, activation='relu'), Dropout(0.5), Dense(128, activation='relu')]\n",
    "vgg_input, vgg_output = create_vgg16_model(custom_layers=custom_layers_vgg)\n",
    "additional_input = create_additional_input((additional_features.shape[1],))\n",
    "additional_layers = [Dense(128, activation='relu'), Dropout(0.5)]\n",
    "model_vgg = create_combined_model(vgg_input, vgg_output, additional_input, additional_layers=additional_layers)\n",
    "\n",
    "custom_callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "]\n",
    "history_vgg = compile_and_train_model(model_vgg, X_train_img, X_train_feat, y_train, X_test_img, X_test_feat, y_test, callbacks=custom_callbacks)\n",
    "\n",
    "model_save_path = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\vgg16_with_additional_features.h5'\n",
    "evaluate_and_save_model(model_vgg, X_test_img, X_test_feat, y_test, model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m 8/34\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:12\u001b[0m 19s/step - accuracy: 0.3296 - loss: 1.5173"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage example for EfficientNetB0\n",
    "csv_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\remaining_dataset.csv'\n",
    "df = load_csv(csv_file)\n",
    "labels = extract_labels(df)\n",
    "additional_features = extract_additional_features(df, ['HbA1c', 'Systolic_BP', 'Diastolic_BP', 'LDL', 'Duration', 'BMI', 'Glucose_SD', 'Triglycerides', 'Microalbuminuria', 'Smoking_years', 'Alcohol_frequency'])\n",
    "additional_features, scaler = normalize_features(additional_features)\n",
    "scaler_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\additional_features_scaler.pkl'\n",
    "save_scaler(scaler, scaler_file)\n",
    "images = load_images(df['full_path'])\n",
    "X_train_img, X_test_img, X_train_feat, X_test_feat, y_train, y_test = split_data(images, additional_features, labels)\n",
    "\n",
    "custom_layers_efficientnet = [GlobalAveragePooling2D(), Dense(256, activation='relu'), Dropout(0.5), Dense(128, activation='relu')]\n",
    "efficientnet_input, efficientnet_output = create_efficientnetb0_model(custom_layers=custom_layers_efficientnet)\n",
    "additional_input = create_additional_input((additional_features.shape[1],))\n",
    "additional_layers = [Dense(128, activation='relu'), Dropout(0.5)]\n",
    "model_efficientnet = create_combined_model(efficientnet_input, efficientnet_output, additional_input, additional_layers=additional_layers)\n",
    "\n",
    "custom_callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "]\n",
    "history_efficientnet = compile_and_train_model(model_efficientnet, X_train_img, X_train_feat, y_train, X_test_img, X_test_feat, y_test, callbacks=custom_callbacks)\n",
    "\n",
    "model_efficientnet_save_path = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\efficientnet_with_additional_features.h5'\n",
    "evaluate_and_save_model(model_efficientnet, X_test_img, X_test_feat, y_test, model_efficientnet_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m 2/34\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:37\u001b[0m 35s/step - accuracy: 0.1484 - loss: 2.0969   "
     ]
    }
   ],
   "source": [
    "# Usage example for ResNet50\n",
    "csv_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\remaining_dataset.csv'\n",
    "df = load_csv(csv_file)\n",
    "labels = extract_labels(df)\n",
    "additional_features = extract_additional_features(df, ['HbA1c', 'Systolic_BP', 'Diastolic_BP', 'LDL', 'Duration', 'BMI', 'Glucose_SD', 'Triglycerides', 'Microalbuminuria', 'Smoking_years', 'Alcohol_frequency'])\n",
    "additional_features, scaler = normalize_features(additional_features)\n",
    "scaler_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\additional_features_scaler.pkl'\n",
    "save_scaler(scaler, scaler_file)\n",
    "images = load_images(df['full_path'])\n",
    "X_train_img, X_test_img, X_train_feat, X_test_feat, y_train, y_test = split_data(images, additional_features, labels)\n",
    "\n",
    "custom_layers_resnet = [GlobalAveragePooling2D(), Dense(256, activation='relu'), Dropout(0.5), Dense(128, activation='relu')]\n",
    "resnet_input, resnet_output = create_resnet50_model(custom_layers=custom_layers_resnet)\n",
    "additional_input = create_additional_input((additional_features.shape[1],))\n",
    "additional_layers = [Dense(128, activation='relu'), Dropout(0.5)]\n",
    "model_resnet = create_combined_model(resnet_input, resnet_output, additional_input, additional_layers=additional_layers)\n",
    "\n",
    "custom_callbacks = [\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001),\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "]\n",
    "history_resnet = compile_and_train_model(model_resnet, X_train_img, X_train_feat, y_train, X_test_img, X_test_feat, y_test, callbacks=custom_callbacks)\n",
    "\n",
    "model_resnet_save_path = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\resnet_with_additional_features.h5'\n",
    "evaluate_and_save_model(model_resnet, X_test_img, X_test_feat, y_test, model_resnet_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved installed packages to requirements.txt\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "\n",
    "# Function to get installed packages\n",
    "def get_installed_packages():\n",
    "    installed_packages = []\n",
    "    for package in pkg_resources.working_set:\n",
    "        installed_packages.append(package.project_name)\n",
    "    return installed_packages\n",
    "\n",
    "# Get installed packages\n",
    "installed_packages = get_installed_packages()\n",
    "\n",
    "# Write to requirements.txt\n",
    "with open('requirements.txt', 'w') as f:\n",
    "    for package in installed_packages:\n",
    "        f.write(package + '\\n')\n",
    "\n",
    "print(\"Successfully saved installed packages to requirements.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
