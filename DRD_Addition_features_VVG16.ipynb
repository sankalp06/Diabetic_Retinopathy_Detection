{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled records:\n",
      "           image  level  PatientId  eye         level_cat      HbA1c  \\\n",
      "0      9103_left      0       9103    1  [1. 0. 0. 0. 0.]   5.859674   \n",
      "1     12948_left      0      12948    1  [1. 0. 0. 0. 0.]   5.608829   \n",
      "2     15859_left      0      15859    1  [1. 0. 0. 0. 0.]   6.569314   \n",
      "3    19968_right      0      19968    0  [1. 0. 0. 0. 0.]   6.636184   \n",
      "4      4197_left      0       4197    1  [1. 0. 0. 0. 0.]   6.334123   \n",
      "..           ...    ...        ...  ...               ...        ...   \n",
      "145  33080_right      4      33080    0  [0. 0. 0. 0. 1.]  10.094568   \n",
      "146  32148_right      4      32148    0  [0. 0. 0. 0. 1.]  10.364584   \n",
      "147   3563_right      4       3563    0  [0. 0. 0. 0. 1.]  10.547997   \n",
      "148  13664_right      4      13664    0  [0. 0. 0. 0. 1.]  10.322404   \n",
      "149  39081_right      4      39081    0  [0. 0. 0. 0. 1.]  10.825708   \n",
      "\n",
      "     Systolic_BP  Diastolic_BP         LDL   Duration        BMI  Glucose_SD  \\\n",
      "0     116.050591     75.564766   70.649708   2.276912  22.487565   17.563625   \n",
      "1     116.753458     74.281117   90.475832   3.224083  23.760227   17.048068   \n",
      "2     117.453273     71.431997   93.741041   1.675487  23.994736   13.058138   \n",
      "3     111.470219     71.741173   97.158513   1.176373  21.385428   15.235148   \n",
      "4     110.606389     70.884653   74.895986   2.223053  22.067743   17.376586   \n",
      "..           ...           ...         ...        ...        ...         ...   \n",
      "145   159.155838     96.627271  215.295885  20.342640  44.114083   36.841094   \n",
      "146   154.343758     95.026587  215.224219  24.782355  42.034426   38.428418   \n",
      "147   159.722037     98.237067  211.311586  23.018906  42.977547   31.940239   \n",
      "148   156.662182     98.249204  205.725745  21.699871  43.380833   39.985192   \n",
      "149   156.441970     96.096635  197.945500  21.094453  44.310005   30.685309   \n",
      "\n",
      "     Triglycerides  Microalbuminuria  Smoking_years  Alcohol_frequency  \\\n",
      "0        82.099102         16.108735              0                  0   \n",
      "1       131.465312          6.013753              4                  0   \n",
      "2        98.965860         27.401670              4                  0   \n",
      "3        98.316463         23.986355              3                  1   \n",
      "4        70.107565          7.107350              2                  0   \n",
      "..             ...               ...            ...                ...   \n",
      "145     303.180946        128.931751             21                  7   \n",
      "146     346.101237        147.007976             24                  6   \n",
      "147     346.816118        122.716356             20                  7   \n",
      "148     345.606729        126.161301             22                  7   \n",
      "149     310.534125        141.314421             20                  7   \n",
      "\n",
      "             BP                                          full_path  \n",
      "0    114.375841  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "1    115.071763  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "2    119.682857  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "3    111.931545  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "4    115.933079  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "..          ...                                                ...  \n",
      "145  159.790399  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "146  153.927208  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "147  152.472969  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "148  153.442016  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "149  159.708850  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "\n",
      "[150 rows x 18 columns]\n",
      "\n",
      "Remaining records:\n",
      "            image  level  PatientId  eye         level_cat      HbA1c  \\\n",
      "0     11204_right      0      11204    0  [1. 0. 0. 0. 0.]   6.664607   \n",
      "1     12793_right      0      12793    0  [1. 0. 0. 0. 0.]   5.569154   \n",
      "2     10614_right      0      10614    0  [1. 0. 0. 0. 0.]   5.673113   \n",
      "3     10046_right      0      10046    0  [1. 0. 0. 0. 0.]   5.819946   \n",
      "4     17936_right      0      17936    0  [1. 0. 0. 0. 0.]   6.943961   \n",
      "...           ...    ...        ...  ...               ...        ...   \n",
      "2675    9419_left      4       9419    1  [0. 0. 0. 0. 1.]  10.233574   \n",
      "2676    9353_left      4       9353    1  [0. 0. 0. 0. 1.]  10.507090   \n",
      "2677     986_left      4        986    1  [0. 0. 0. 0. 1.]  10.895387   \n",
      "2678    9311_left      4       9311    1  [0. 0. 0. 0. 1.]  10.724021   \n",
      "2679    8950_left      4       8950    1  [0. 0. 0. 0. 1.]  10.437743   \n",
      "\n",
      "      Systolic_BP  Diastolic_BP         LDL   Duration        BMI  Glucose_SD  \\\n",
      "0      118.160623     73.009563   95.632704   3.173715  23.683483   13.023127   \n",
      "1      114.915966     77.979362   98.923421   1.792701  23.139272   12.654202   \n",
      "2      114.006031     75.306831   81.936662   4.964299  23.275760   17.254322   \n",
      "3      119.703647     75.263489   83.784645   2.611829  21.164522   12.427103   \n",
      "4      113.874062     78.335375   97.558886   3.736780  21.516293   16.995806   \n",
      "...           ...           ...         ...        ...        ...         ...   \n",
      "2675   157.146320     96.005777  191.161692  23.370664  44.840187   35.697004   \n",
      "2676   152.637399     96.800907  215.467928  24.183682  44.162003   38.955630   \n",
      "2677   153.850578     99.164646  204.158561  21.608763  41.668109   38.077704   \n",
      "2678   159.621068     96.939783  206.914166  20.856461  43.874057   31.679422   \n",
      "2679   151.969565     96.446953  199.397063  21.822586  41.626222   37.796002   \n",
      "\n",
      "      Triglycerides  Microalbuminuria  Smoking_years  Alcohol_frequency  \\\n",
      "0        116.933755          8.170038              4                  0   \n",
      "1         56.645795          2.261660              0                  0   \n",
      "2         60.284675         16.585806              0                  0   \n",
      "3        112.322626          7.779978              4                  0   \n",
      "4         55.465491         20.792241              0                  0   \n",
      "...             ...               ...            ...                ...   \n",
      "2675     301.006105        131.534725             24                  7   \n",
      "2676     329.492377        135.479981             25                  4   \n",
      "2677     307.049078        130.212946             21                  7   \n",
      "2678     334.567157        128.017748             23                  7   \n",
      "2679     309.097981        141.135258             20                  5   \n",
      "\n",
      "              BP                                          full_path  \n",
      "0     113.702971  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "1     112.601676  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "2     119.270236  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "3     115.776956  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "4     117.560609  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "...          ...                                                ...  \n",
      "2675  154.474343  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "2676  156.335031  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "2677  153.319608  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "2678  152.287227  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "2679  151.881673  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
      "\n",
      "[2680 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your dataset is in a CSV file\n",
    "file_path = r'inference_drd\\Diabetic_Retinopathy_Detection\\train.csv'\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['Unnamed: 0', 'path', 'exists']  # Add any other columns you want to drop\n",
    "\n",
    "# Drop the specified columns\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Function to sample 30 records from each level\n",
    "def sample_and_remove(group, n=30):\n",
    "    sampled = group.sample(n=min(len(group), n), random_state=1)\n",
    "    remaining = group.drop(sampled.index)\n",
    "    return sampled, remaining\n",
    "\n",
    "# Initialize empty lists to store sampled and remaining DataFrames\n",
    "sampled_list = []\n",
    "remaining_list = []\n",
    "\n",
    "# Group by 'level' and apply the sampling function\n",
    "for name, group in df.groupby('level'):\n",
    "    sampled, remaining = sample_and_remove(group)\n",
    "    sampled_list.append(sampled)\n",
    "    remaining_list.append(remaining)\n",
    "\n",
    "# Concatenate the sampled and remaining DataFrames\n",
    "sampled_df = pd.concat(sampled_list, ignore_index=True)\n",
    "remaining_df = pd.concat(remaining_list, ignore_index=True)\n",
    "\n",
    "# Save or display the sampled DataFrame\n",
    "sampled_df.to_csv('sampled_dataset.csv', index=False)\n",
    "print(\"Sampled records:\")\n",
    "print(sampled_df)\n",
    "\n",
    "# Save or display the remaining DataFrame\n",
    "remaining_df.to_csv('remaining_dataset.csv', index=False)\n",
    "print(\"\\nRemaining records:\")\n",
    "print(remaining_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "      <th>PatientId</th>\n",
       "      <th>path</th>\n",
       "      <th>exists</th>\n",
       "      <th>eye</th>\n",
       "      <th>level_cat</th>\n",
       "      <th>HbA1c</th>\n",
       "      <th>Systolic_BP</th>\n",
       "      <th>...</th>\n",
       "      <th>LDL</th>\n",
       "      <th>Duration</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose_SD</th>\n",
       "      <th>Triglycerides</th>\n",
       "      <th>Microalbuminuria</th>\n",
       "      <th>Smoking_years</th>\n",
       "      <th>Alcohol_frequency</th>\n",
       "      <th>BP</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11204_right</td>\n",
       "      <td>0</td>\n",
       "      <td>11204</td>\n",
       "      <td>.\\train.zip.001\\train\\train\\11204_right.jpeg</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 0. 0. 0.]</td>\n",
       "      <td>6.664607</td>\n",
       "      <td>118.160623</td>\n",
       "      <td>...</td>\n",
       "      <td>95.632704</td>\n",
       "      <td>3.173715</td>\n",
       "      <td>23.683483</td>\n",
       "      <td>13.023127</td>\n",
       "      <td>116.933755</td>\n",
       "      <td>8.170038</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>113.702971</td>\n",
       "      <td>E:\\Computer_Vision_projects\\Diabetic_retinopat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12793_right</td>\n",
       "      <td>0</td>\n",
       "      <td>12793</td>\n",
       "      <td>.\\train.zip.001\\train\\train\\12793_right.jpeg</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 0. 0. 0.]</td>\n",
       "      <td>5.569154</td>\n",
       "      <td>114.915966</td>\n",
       "      <td>...</td>\n",
       "      <td>98.923421</td>\n",
       "      <td>1.792701</td>\n",
       "      <td>23.139272</td>\n",
       "      <td>12.654202</td>\n",
       "      <td>56.645795</td>\n",
       "      <td>2.261660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.601676</td>\n",
       "      <td>E:\\Computer_Vision_projects\\Diabetic_retinopat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10614_right</td>\n",
       "      <td>0</td>\n",
       "      <td>10614</td>\n",
       "      <td>.\\train.zip.001\\train\\train\\10614_right.jpeg</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 0. 0. 0.]</td>\n",
       "      <td>5.673113</td>\n",
       "      <td>114.006031</td>\n",
       "      <td>...</td>\n",
       "      <td>81.936662</td>\n",
       "      <td>4.964299</td>\n",
       "      <td>23.275760</td>\n",
       "      <td>17.254322</td>\n",
       "      <td>60.284675</td>\n",
       "      <td>16.585806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>119.270236</td>\n",
       "      <td>E:\\Computer_Vision_projects\\Diabetic_retinopat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10046_right</td>\n",
       "      <td>0</td>\n",
       "      <td>10046</td>\n",
       "      <td>.\\train.zip.001\\train\\train\\10046_right.jpeg</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 0. 0. 0.]</td>\n",
       "      <td>5.819946</td>\n",
       "      <td>119.703647</td>\n",
       "      <td>...</td>\n",
       "      <td>83.784645</td>\n",
       "      <td>2.611829</td>\n",
       "      <td>21.164522</td>\n",
       "      <td>12.427103</td>\n",
       "      <td>112.322626</td>\n",
       "      <td>7.779978</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>115.776956</td>\n",
       "      <td>E:\\Computer_Vision_projects\\Diabetic_retinopat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17936_right</td>\n",
       "      <td>0</td>\n",
       "      <td>17936</td>\n",
       "      <td>.\\train.zip.001\\train\\train\\17936_right.jpeg</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[1. 0. 0. 0. 0.]</td>\n",
       "      <td>6.943961</td>\n",
       "      <td>113.874062</td>\n",
       "      <td>...</td>\n",
       "      <td>97.558886</td>\n",
       "      <td>3.736780</td>\n",
       "      <td>21.516293</td>\n",
       "      <td>16.995806</td>\n",
       "      <td>55.465491</td>\n",
       "      <td>20.792241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117.560609</td>\n",
       "      <td>E:\\Computer_Vision_projects\\Diabetic_retinopat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        image  level  PatientId  \\\n",
       "0           0  11204_right      0      11204   \n",
       "1           1  12793_right      0      12793   \n",
       "2           2  10614_right      0      10614   \n",
       "3           3  10046_right      0      10046   \n",
       "4           4  17936_right      0      17936   \n",
       "\n",
       "                                           path  exists  eye  \\\n",
       "0  .\\train.zip.001\\train\\train\\11204_right.jpeg    True    0   \n",
       "1  .\\train.zip.001\\train\\train\\12793_right.jpeg    True    0   \n",
       "2  .\\train.zip.001\\train\\train\\10614_right.jpeg    True    0   \n",
       "3  .\\train.zip.001\\train\\train\\10046_right.jpeg    True    0   \n",
       "4  .\\train.zip.001\\train\\train\\17936_right.jpeg    True    0   \n",
       "\n",
       "          level_cat     HbA1c  Systolic_BP  ...        LDL  Duration  \\\n",
       "0  [1. 0. 0. 0. 0.]  6.664607   118.160623  ...  95.632704  3.173715   \n",
       "1  [1. 0. 0. 0. 0.]  5.569154   114.915966  ...  98.923421  1.792701   \n",
       "2  [1. 0. 0. 0. 0.]  5.673113   114.006031  ...  81.936662  4.964299   \n",
       "3  [1. 0. 0. 0. 0.]  5.819946   119.703647  ...  83.784645  2.611829   \n",
       "4  [1. 0. 0. 0. 0.]  6.943961   113.874062  ...  97.558886  3.736780   \n",
       "\n",
       "         BMI  Glucose_SD  Triglycerides  Microalbuminuria  Smoking_years  \\\n",
       "0  23.683483   13.023127     116.933755          8.170038              4   \n",
       "1  23.139272   12.654202      56.645795          2.261660              0   \n",
       "2  23.275760   17.254322      60.284675         16.585806              0   \n",
       "3  21.164522   12.427103     112.322626          7.779978              4   \n",
       "4  21.516293   16.995806      55.465491         20.792241              0   \n",
       "\n",
       "   Alcohol_frequency          BP  \\\n",
       "0                  0  113.702971   \n",
       "1                  0  112.601676   \n",
       "2                  0  119.270236   \n",
       "3                  0  115.776956   \n",
       "4                  0  117.560609   \n",
       "\n",
       "                                           full_path  \n",
       "0  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
       "1  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
       "2  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
       "3  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
       "4  E:\\Computer_Vision_projects\\Diabetic_retinopat...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./inference_drd/Diabetic_Retinopathy_Detection/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'image', 'level', 'PatientId', 'path', 'exists', 'eye',\n",
       "       'level_cat', 'HbA1c', 'Systolic_BP', 'Diastolic_BP', 'LDL', 'Duration',\n",
       "       'BMI', 'Glucose_SD', 'Triglycerides', 'Microalbuminuria',\n",
       "       'Smoking_years', 'Alcohol_frequency', 'BP', 'full_path'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2072s\u001b[0m 61s/step - accuracy: 0.2270 - loss: 2.9909 - val_accuracy: 0.3060 - val_loss: 1.5227 - learning_rate: 1.0000e-04\n",
      "Epoch 2/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2050s\u001b[0m 60s/step - accuracy: 0.2898 - loss: 1.5439 - val_accuracy: 0.3899 - val_loss: 1.3522 - learning_rate: 1.0000e-04\n",
      "Epoch 3/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2191s\u001b[0m 65s/step - accuracy: 0.3934 - loss: 1.3843 - val_accuracy: 0.5728 - val_loss: 1.2044 - learning_rate: 1.0000e-04\n",
      "Epoch 4/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2415s\u001b[0m 71s/step - accuracy: 0.4342 - loss: 1.2950 - val_accuracy: 0.7239 - val_loss: 1.1149 - learning_rate: 1.0000e-04\n",
      "Epoch 5/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2630s\u001b[0m 78s/step - accuracy: 0.5018 - loss: 1.2098 - val_accuracy: 0.6959 - val_loss: 1.0707 - learning_rate: 1.0000e-04\n",
      "Epoch 6/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2774s\u001b[0m 82s/step - accuracy: 0.5542 - loss: 1.1388 - val_accuracy: 0.6362 - val_loss: 1.0226 - learning_rate: 1.0000e-04\n",
      "Epoch 7/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2456s\u001b[0m 72s/step - accuracy: 0.5962 - loss: 1.0753 - val_accuracy: 0.9291 - val_loss: 0.9293 - learning_rate: 1.0000e-04\n",
      "Epoch 8/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2113s\u001b[0m 62s/step - accuracy: 0.6046 - loss: 1.0286 - val_accuracy: 0.9216 - val_loss: 0.8979 - learning_rate: 1.0000e-04\n",
      "Epoch 9/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2049s\u001b[0m 60s/step - accuracy: 0.6296 - loss: 1.0005 - val_accuracy: 0.9646 - val_loss: 0.8347 - learning_rate: 1.0000e-04\n",
      "Epoch 10/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2032s\u001b[0m 60s/step - accuracy: 0.6406 - loss: 0.9506 - val_accuracy: 0.9123 - val_loss: 0.8129 - learning_rate: 1.0000e-04\n",
      "Epoch 11/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2037s\u001b[0m 60s/step - accuracy: 0.6664 - loss: 0.9031 - val_accuracy: 0.9608 - val_loss: 0.7724 - learning_rate: 1.0000e-04\n",
      "Epoch 12/12\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2020s\u001b[0m 59s/step - accuracy: 0.7052 - loss: 0.8608 - val_accuracy: 0.9384 - val_loss: 0.7513 - learning_rate: 1.0000e-04\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 5s/step - accuracy: 0.9357 - loss: 0.7557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7512641549110413, Accuracy: 0.9384328126907349\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle \n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\remaining_dataset.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Fix the format of level_cat and extract labels\n",
    "def fix_level_cat_format(row):\n",
    "    return eval(row.replace(' ', ', '))\n",
    "\n",
    "labels = np.array([fix_level_cat_format(row) for row in df['level_cat'].values])\n",
    "\n",
    "# Extract additional features\n",
    "additional_features = df[['HbA1c', 'Systolic_BP', 'Diastolic_BP', 'LDL', 'Duration', \n",
    "                          'BMI', 'Glucose_SD', 'Triglycerides', 'Microalbuminuria', \n",
    "                          'Smoking_years', 'Alcohol_frequency']].values\n",
    "\n",
    "# Normalize additional features\n",
    "scaler = StandardScaler()\n",
    "additional_features = scaler.fit_transform(additional_features)\n",
    "\n",
    "# Save the scaler object\n",
    "scaler_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\additional_features_scaler.pkl'\n",
    "with open(scaler_file, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "images = np.array([load_and_preprocess_image(path) for path in df['full_path']])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_img, X_test_img, X_train_feat, X_test_feat, y_train, y_test = train_test_split(\n",
    "    images, additional_features, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "### Step 2: Modify the VGG16 Model\n",
    "\n",
    "# Load VGG16 model without the top layers\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom top layers\n",
    "x = vgg16.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "vgg_output = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Define additional features input\n",
    "additional_input = Input(shape=(additional_features.shape[1],))\n",
    "\n",
    "### Step 3: Combine the VGG16 Output and Additional Features\n",
    "\n",
    "# Combine VGG16 output and additional features\n",
    "combined = concatenate([vgg_output, additional_input])\n",
    "\n",
    "# Add more dense layers if needed\n",
    "combined = Dense(128, activation='relu')(combined)\n",
    "combined = Dropout(0.5)(combined)\n",
    "final_output = Dense(5, activation='softmax')(combined)  # Assuming five classes for multi-class classification\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=[vgg16.input, additional_input], outputs=final_output)\n",
    "\n",
    "### Step 4: Compile and Train the Model\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [X_train_img, X_train_feat], y_train,\n",
    "    validation_data=([X_test_img, X_test_feat], y_test),\n",
    "    epochs=12,  # Increased number of epochs to make use of EarlyStopping\n",
    "    batch_size=64,\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n",
    "\n",
    "### Step 5: Evaluate and Save the Model\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([X_test_img, X_test_feat], y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "model.save(r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\vgg16_with_additional_features.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888ms/step\n",
      "Predicted class for left eye: 4 with confidence 0.6738\n",
      "Predicted class for right eye: 4 with confidence 0.6609\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Suppress TensorFlow logs and oneDNN custom operations\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress all TensorFlow logs\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable oneDNN custom operations\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Further suppress TensorFlow logging\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "# Load your saved model\n",
    "model = tf.keras.models.load_model(r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\vgg16_with_additional_features.h5', custom_objects=None, compile=True, safe_mode=True)\n",
    "\n",
    "# Function to load and preprocess image\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# Function to load the scaler\n",
    "def load_scaler(scaler_file):\n",
    "    with open(scaler_file, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    return scaler\n",
    "\n",
    "# Function to predict class for a single record\n",
    "def predict_single_record(left_eye_path, right_eye_path, additional_features, scaler):\n",
    "    # Load and preprocess images\n",
    "    left_eye_img = load_and_preprocess_image(left_eye_path)\n",
    "    right_eye_img = load_and_preprocess_image(right_eye_path)\n",
    "\n",
    "    # Convert additional features to numpy array and scale using loaded scaler\n",
    "    additional_features = np.array(additional_features).reshape(1, -1)\n",
    "    additional_features_scaled = scaler.transform(additional_features)\n",
    "\n",
    "    # Repeat additional features to match the number of images (left and right eye)\n",
    "    additional_features_repeated = np.repeat(additional_features_scaled, 2, axis=0)\n",
    "\n",
    "    # Stack images to create a batch of size 2 (left and right eye)\n",
    "    images = np.stack([left_eye_img, right_eye_img], axis=0)\n",
    "\n",
    "    # Temporarily suppress warnings during prediction\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Predict for both eyes\n",
    "        predictions = model.predict([images, additional_features_repeated])\n",
    "    \n",
    "    # Assuming predictions are probabilities for each class, extract the predicted class and confidence\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    confidences = np.max(predictions, axis=1)\n",
    "    \n",
    "    return predicted_classes, confidences\n",
    "\n",
    "# Paths to left and right eye images\n",
    "left_eye_path = 'E:/Computer_Vision_projects/Diabetic_retinopathy_detection/train.zip.001/train/train/10_left.jpeg'\n",
    "right_eye_path = 'E:/Computer_Vision_projects/Diabetic_retinopathy_detection/train.zip.001/train/train/10_right.jpeg'\n",
    "\n",
    "# Path to the scaler file\n",
    "scaler_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\additional_features_scaler.pkl'\n",
    "\n",
    "# Load the scaler\n",
    "scaler = load_scaler(scaler_file)\n",
    "\n",
    "# Example additional features (replace with your own)\n",
    "additional_features = [\n",
    "    10.896195065561075,  # HbA1c\n",
    "    150.69693481299157,  # Systolic_BP\n",
    "    97.58934460717728,   # Diastolic_BP\n",
    "    193.71066317092425,  # LDL\n",
    "    21.41599013207625,   # Duration\n",
    "    41.20415312086392,   # BMI\n",
    "    30.84676095056483,   # Glucose_SD\n",
    "    311.23456504422853,  # Triglycerides\n",
    "    120.01877115621907,  # Microalbuminuria\n",
    "    23,                  # Smoking_years\n",
    "    6,                   # Alcohol_frequency\n",
    "]\n",
    "\n",
    "# Get predictions and confidences\n",
    "predicted_classes, confidences = predict_single_record(left_eye_path, right_eye_path, additional_features, scaler)\n",
    "\n",
    "# Output predictions and confidences for left and right eye\n",
    "print(f'Predicted class for left eye: {predicted_classes[0]} with confidence {confidences[0]:.4f}')\n",
    "print(f'Predicted class for right eye: {predicted_classes[1]} with confidence {confidences[1]:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6s/step\n",
      "Accuracy: 0.9667\n",
      "Precision: 0.9693\n",
      "Recall: 0.9667\n",
      "F1 Score: 0.9666\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,  confusion_matrix, classification_report\n",
    "\n",
    "# Suppress TensorFlow logs and oneDNN custom operations\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress all TensorFlow logs\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable oneDNN custom operations\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Further suppress TensorFlow logging\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(3)\n",
    "\n",
    "# Load your saved model\n",
    "model = tf.keras.models.load_model(r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\vgg16_with_additional_features.h5')\n",
    "\n",
    "# Function to load and preprocess image\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# Function to load the scaler\n",
    "def load_scaler(scaler_file):\n",
    "    with open(scaler_file, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    return scaler\n",
    "\n",
    "# Fix the format of level_cat and extract labels\n",
    "def fix_level_cat_format(row):\n",
    "    return eval(row.replace(' ', ', '))\n",
    "\n",
    "# Function to predict class for multiple records\n",
    "def predict_records(df, scaler):\n",
    "    images = []\n",
    "    additional_features = []\n",
    "    true_labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        left_eye_img = load_and_preprocess_image(row['full_path'])\n",
    "        images.append(left_eye_img)\n",
    "        additional_features.append([\n",
    "            row['HbA1c'], row['Systolic_BP'], row['Diastolic_BP'], row['LDL'], \n",
    "            row['Duration'], row['BMI'], row['Glucose_SD'], row['Triglycerides'], \n",
    "            row['Microalbuminuria'], row['Smoking_years'], row['Alcohol_frequency']\n",
    "        ])\n",
    "        true_labels.append(fix_level_cat_format(row['level_cat']))  # Fix the format of level_cat\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    images = np.array(images)\n",
    "    additional_features = np.array(additional_features)\n",
    "    true_labels = np.array(true_labels)\n",
    "\n",
    "    # Scale additional features using the loaded scaler\n",
    "    additional_features_scaled = scaler.transform(additional_features)\n",
    "\n",
    "    # Predict using the model\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        predictions = model.predict([images, additional_features_scaled])\n",
    "\n",
    "    # Extract the predicted classes\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(true_labels, axis=1)\n",
    "\n",
    "    return true_classes, predicted_classes\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\sampled_dataset.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Path to the scaler file\n",
    "scaler_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\additional_features_scaler.pkl'\n",
    "\n",
    "# Load the scaler\n",
    "scaler = load_scaler(scaler_file)\n",
    "\n",
    "# Predict for all records in the CSV\n",
    "true_classes, predicted_classes = predict_records(df, scaler)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(true_classes, predicted_classes, target_names=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'])\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[30  0  0  0  0]\n",
      " [ 2 28  0  0  0]\n",
      " [ 0  0 30  0  0]\n",
      " [ 0  0  0 27  3]\n",
      " [ 0  0  0  0 30]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.94      1.00      0.97        30\n",
      "     Class 1       1.00      0.93      0.97        30\n",
      "     Class 2       1.00      1.00      1.00        30\n",
      "     Class 3       1.00      0.90      0.95        30\n",
      "     Class 4       0.91      1.00      0.95        30\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(true_classes, predicted_classes, target_names=['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4'])\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load_csv(csv_file):\n",
    "    return pd.read_csv(csv_file)\n",
    "\n",
    "def fix_level_cat_format(row):\n",
    "    return eval(row.replace(' ', ', '))\n",
    "\n",
    "def extract_labels(df):\n",
    "    return np.array([fix_level_cat_format(row) for row in df['level_cat'].values])\n",
    "\n",
    "def extract_additional_features(df):\n",
    "    return df[['HbA1c', 'Systolic_BP', 'Diastolic_BP', 'LDL', 'Duration', \n",
    "               'BMI', 'Glucose_SD', 'Triglycerides', 'Microalbuminuria', \n",
    "               'Smoking_years', 'Alcohol_frequency']].values\n",
    "\n",
    "def normalize_features(features):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    return scaled_features, scaler\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def load_images(image_paths):\n",
    "    return np.array([load_and_preprocess_image(path) for path in image_paths])\n",
    "\n",
    "def split_data(images, additional_features, labels, test_size=0.2, random_state=42):\n",
    "    return train_test_split(images, additional_features, labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def save_scaler(scaler, scaler_file):\n",
    "    with open(scaler_file, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "def create_vgg16_model(input_shape=(224, 224, 3)):\n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = vgg16.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    vgg_output = Dense(128, activation='relu')(x)\n",
    "    return vgg16.input, vgg_output\n",
    "\n",
    "def create_additional_input(input_shape):\n",
    "    return Input(shape=input_shape)\n",
    "\n",
    "def create_combined_model(vgg_input, vgg_output, additional_input, num_classes=5):\n",
    "    combined = concatenate([vgg_output, additional_input])\n",
    "    combined = Dense(128, activation='relu')(combined)\n",
    "    combined = Dropout(0.5)(combined)\n",
    "    final_output = Dense(num_classes, activation='softmax')(combined)\n",
    "    return Model(inputs=[vgg_input, additional_input], outputs=final_output)\n",
    "\n",
    "def compile_and_train_model(model, X_train_img, X_train_feat, y_train, X_test_img, X_test_feat, y_test, epochs=12, batch_size=64):\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        [X_train_img, X_train_feat], y_train,\n",
    "        validation_data=([X_test_img, X_test_feat], y_test),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[reduce_lr, early_stopping]\n",
    "    )\n",
    "    return history\n",
    "\n",
    "def evaluate_and_save_model(model, X_test_img, X_test_feat, y_test, model_save_path):\n",
    "    loss, accuracy = model.evaluate([X_test_img, X_test_feat], y_test)\n",
    "    print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
    "    model.save(model_save_path)\n",
    "\n",
    "\n",
    "csv_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\remaining_dataset.csv'\n",
    "\n",
    "scaler_file = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\additional_features_scaler.pkl'\n",
    "\n",
    "model_save_path = r'E:\\Computer_Vision_projects\\inference_drd\\Diabetic_Retinopathy_Detection\\vgg16_with_additional_features.h5'\n",
    "\n",
    "df = load_csv(csv_file)\n",
    "\n",
    "labels = extract_labels(df)\n",
    "\n",
    "additional_features = extract_additional_features(df)\n",
    "\n",
    "additional_features, scaler = normalize_features(additional_features)\n",
    "\n",
    "save_scaler(scaler, scaler_file)\n",
    "\n",
    "images = load_images(df['full_path'])\n",
    "\n",
    "X_train_img, X_test_img, X_train_feat, X_test_feat, y_train, y_test = split_data(images, additional_features, labels)\n",
    "\n",
    "vgg_input, vgg_output = create_vgg16_model()\n",
    "\n",
    "additional_input = create_additional_input((additional_features.shape[1],))\n",
    "\n",
    "model = create_combined_model(vgg_input, vgg_output, additional_input)\n",
    "\n",
    "history = compile_and_train_model(model, X_train_img, X_train_feat, y_train, X_test_img, X_test_feat, y_test)\n",
    "\n",
    "evaluate_and_save_model(model, X_test_img, X_test_feat, y_test, model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
